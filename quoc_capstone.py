# -*- coding: utf-8 -*-
"""quoc capstone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1blzsaakRoN0hwBe_fBRUnHi5X3eqdXkU

### **ST1/ST1G Assignment 9 (Capstone Programming Project)**
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = '/content'

"""## Step 1: Reading the data Reading the data with python"""

import pandas as pd
import numpy as np
diamonds = pd.read_csv('/content/drive/MyDrive/diamonds.csv', encoding='latin')
print('Shape befor deleting duplicate values:', diamonds.shape)

# Removing duplicate rows if any
diamonds=diamonds.drop_duplicates()
print('Shape After deleting duplicate values:', diamonds.shape)

diamonds.head(10)

diamonds.tail(10)

"""Key Observations from Step 1 about Data Description:
This file contains 10 rows of data, likely representing individual diamonds with specific characteristics.

There are 11 attributes in the dataset, outlined below:


Unnamed: 0 - The index or identifier for each diamond.

carat - The weight of the diamond in carats.

cut - The quality of the cut, with possible values like Premium, Ideal, Very Good, etc.

color - The color grade of the diamond, with values like E, F, H, etc.

clarity - The clarity grade, representing the visibility of internal inclusions, such as SI1, VS2, etc.

depth - The total depth percentage of the diamond, calculated as

table - The width of the diamond's table expressed as a percentage of its average diameter.

price - The price of the diamond in USD.

x - The length of the diamond in millimeters.

y - The width of the diamond in millimeters.

z - The depth of the diamond in millimeters.

# **Step 2: Problem Statement Definition**

Creating a prediction model to predict the price of diamonds

Target virable: price

 Predators/Features: carat,cut,color,clarity,depth,table,price,x,y,z.

## **Step 3: Choosing the appropriate ML/AI Algorithm for Data Analysis.**

Based on the problem statement we need to create a supervised ML Regression model, as the target variable is Continuous.

## **Step 4: Looking at the class distribution (Target variable distribution to check if the data is balanced or skewed)**

If target variable's distribution is too skewed then the predictive modeling will lead to poor results.

Ideally Bell curve is desirable but slightly positive skew or negative skew is also fine.

When performing Regression algorithm modelling and analysis, we need to make sure the histogram looks like a bell curve or slight skewed version of it.

Otherwise it impacts the Machine Learning algorithms ability to learn all the scenarios from the data.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# Creating histogram as the Target variable is Continuous
# This will help us to understand the distribution of the diamonds values
diamonds['price'].hist()

# Looking at HEAD in data
diamonds.head()

# Looking at TAIL in data
diamonds.tail()

# Looking at INFO in data
diamonds.info()

# Looking at DESCRIBE in data
diamonds.describe(include='all')

# Looking at unique in data
diamonds.nunique()

# Commented out IPython magic to ensure Python compatibility.
# Plotting multiple bar charts at once for categorical variables
# Since there is no default function which can plot bar charts for multiple columns at once
# we are defining our own function for the same

def PlotBarCharts(inpData, colsToPlot):
#     %matplotlib inline

    import matplotlib.pyplot as plt

    # Generating multiple subplots
    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))
    fig.suptitle('Bar charts of: '+ str(colsToPlot))

    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):
        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])

"""## **Step 7: Removing Unwanted columns**
There are no qualitative columns in the data.

Hence no need to remove any column.

## **Step 8: Visual Exploratory Data Analysis**
"""

# Commented out IPython magic to ensure Python compatibility.
def PlotBarCharts(inpData, colsToPlot):
#   %matplotlib inline
  import matplotlib.pyplot as plt
  # Generating multiple subplots
  fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))
  fig.suptitle('Bar charts of: '+ str(colsToPlot))
  for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):
    inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])
#####################################################################
# Calling the function PlotBarCharts() we have created
PlotBarCharts(inpData=diamonds, colsToPlot=['cut','color','clarity'])

"""Observations from Step 8 - Visual Exploratory Data Analysis (Left for now)

Bar Charts have allowed interpretation on the two data columns

The bar charts represent the frequencies of each category in the Y-axis and the category names in the X-axis.

In the ideal bar chart each category has comparable frequency.

Hence, there are enough rows for each category in the data for the ML/AI regression algorithm to learn.

If there is a column which shows too skewed distribution where there is only one dominant bar and the other categories are present in very low numbers.

These kind of columns may not be very helpful in machine learning model development.

We can confirm this with the correlation analysis step coming up, and take a final call to select or reject the column/data attribute.

In this dataset, it is worth noting that "price" is skewed.
 There is just one bar which is dominating and other one have very less rows.

Such columns may not be correlated with the target variable because there is no information to learn.

The algorithms cannot find any rule like when the value is this then the target variable is that.

## **Step 9: Now Visualize distribution of all the Continuous Predictor variables in the data using histograms**

Based on the Basic Exploratory Data Analysis, there are seven continuous predictor variables "carat", "depth", "table", "price", "x", "y","z".
"""

# Plotting histograms of multiple columns together
diamonds.hist(['carat','depth','table','price','x','y','z'], figsize=(18,10))

"""Observations from Step 9
Histogram Interpretation

Each histograms shows us the data distribution for a single continuous variable.

The X-axis shows the range of values and Y-axis represent the number of values in that range.

For example, in the histogram of open, there are over 40 days that diamonds price reach in closet to $1200.00

Selected Continuous Variables:

carat : Selected. The distribution is good

table : Selected. The distribution is good.

price : Selected. The distribution is good.

x     : Selected. The distrubution is good.

y     : Selected. The distrubution is good.

z     : Selected. The distrubution is good.

depth : Selected. The outliner for 80 are quite low. They needed to be treated as such.

## **Step 10: Outlier Analysis**
Outliers are extreme values in the data which are far away from most of the values.

You can see them as the tails in the histogram.

Outlier must be treated one column/data attribute at a time.

As the treatment will be slightly different for each column

Why I should analyse the outliers?

Outliers bias the building of machine learning models.

As the algorithm tries to fit the extreme value, it goes away from majority of the data.

Outlined below are two options to treat outliers in the data.

Option-1: Delete the outlier Records. Only if there are just few rows lost.

Option-2: Impute the outlier values with a logical business value

Let us find out out the most logical value to be replaced in place of outliers by looking at the histogram.
"""

#Replacing outliers for 'depth'
# Finding nearest values to 70 mark
diamonds['depth'][diamonds['depth']<80].sort_values(ascending=False)

"""Observation: Above result shows the nearest logical value is 79.0, hence, replacing any value above 80 with it."""

# Replacing outliers with nearest possibe value
diamonds['depth'][diamonds['depth']>80] = 79

"""Step 11:Visualising Data Distribution after outlier removal

"""

diamonds.hist(['depth'], figsize=(18,5))

"""## **Step 12: Missing Values Analysis**

Missing values are treated for each column separately.

If a column has more than 30% data missing, then missing value treatment cannot be done.

That column must be rejected because too much information is missing.

Outlined below are some options for treating missing values in data.

Delete the missing value rows if there are only few records

Impute the missing values with MEDIAN value for continuous variables

Impute the missing values with MODE value for categorical variables

Interpolate the values based on nearby values

Interpolate the values based on business logic
"""

# Finding how many missing values are there for each column
diamonds.isnull().sum()

"""## **Observations from Step 12: Missing Value Analysis**

No missing values in data

So no removal is required

### **Step 13: Feature Selection (Attribute Selection)**
"""

ContinuousCols=['carat','depth', 'table','x','y','z']

# Plotting scatter chart for each predictor vs the target variable
for predictor in ContinuousCols:
    diamonds.plot.scatter(x=predictor, y='price', figsize=(10,5), title="price" + " affected by "+predictor)

"""## Scatter charts interpretation
* What should you look for in these scatter charts?

* **Trend.** You should try to see if there is a visible trend or not. There could be three scenarios

* **!!Increasing Trend!!**: This means both variables are positively correlated. In simpler terms, they are directly proportional to each other, if one value increases, other also increases. This is good for ML model building!

* **Decreasing Trend:** This means both variables are negatively correlated. In simpler terms, they are inversely proportional to each other, if one value increases, other decreases. This is also good for ML model building!

* **No Trend**: You cannot see any clear increasing or decreasing trend. This means there is no correlation between the variables. Hence that predictor/feature may not be the best one for ML model building.

* Based on this chart we can get a good idea about the predictor, if it will be useful or not. You confirm this by looking at the correlation value in the next step.

## Step 14: Statistical Feature Selection (Continuous Vs Continuous) using Correlation value

* Pearson's correlation coefficient is a powerful metric for doing this.
* It can simply be calculated as the covariance between two features  x and  y
  (numerator) divided by the product of their standard deviations (denominator):

![image.png](data:image/png;base64,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)

* This value can be calculated only between two numeric columns
Correlation between [-1,0) means inversely proportional, the scatter plot will show a downward trend
* Correlation between (0,1] means directly proportional, the scatter plot will show a upward trend
* Correlation near {0} means No relationship, the scatter plot will show no clear trend.
* If Correlation value between two variables is > 0.5 in magnitude, it indicates good relationship the sign does not matter
* We observe the correlations between Target variable and all other predictor variables(s) to check which columns/features/predictors are actually related to the target variable in question.
"""

# Calculating correlation matrix
ContinuousCols=['carat','depth', 'table','x','y','z','price']

# Creating the correlation matrix
CorrelationData=diamonds[ContinuousCols].corr()
CorrelationData

# Filtering only those columns where absolute correlation > 0.5 with Target Variable
# reduce the 0.5 threshold if no variable is selected
CorrelationData['price'][abs(CorrelationData['price']) > 0.5 ]

"""## Observations from Step 14
* Final selected Continuous columns:

* **'carat','depth', 'table','x','y','z','price'**

# Step 15:  Relationship exploration: Categorical Vs Continuous -- Box Plots
* When the target variable is Continuous and the predictor variable is Categorical we analyze the relation using Boxplots,  and
* Measure the strength of relation using Anova test.
"""

# Box plots for continuous Target Variable "MEDV" and Categorical predictors
CategoricalColsList=['cut', 'color','clarity']

import matplotlib.pyplot as plt
fig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))

# Creating box plots for each continuous predictor against the Target Variable "MEDV"
for PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):
    diamonds.boxplot(column='price', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])

"""##Observations from Step 15: Box-Plots interpretation

* What should you look for in these box plots?

* These plots gives an idea about the data distribution of continuous predictor in the Y-axis for each of the category in the X-Axis.

* If the distribution looks similar for each category(Boxes are in the same line), that means the the continuous variable has NO effect on the target variable. Hence, the variables are not correlated to each other.

* On the other hand if the distribution is different for each category(the boxes are not in same line!). It hints that these variables might be correlated with price.

* For this datadata, both the categorical predictors looks correlated with the Target variable.

We confirm this by looking at the results of ANOVA test below

## Step 16: Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test

* Analysis of variance(ANOVA) is performed to check if there is any relationship between the given continuous and categorical variable

* Assumption(H0) Null Hypothesis: There is NO relation between the given variables (i.e.
* The average(mean) values of the numeric Target variable is same for all the groups in the categorical Predictor variable)
* ANOVA Test result: Probability of H0 (Null Hypothesis being true
"""

# Defining a function to find the statistical relationship with all the categorical variables
def FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):
    from scipy.stats import f_oneway

    # Creating an empty list of final selected predictors
    SelectedPredictors=[]

    print('##### ANOVA Results ##### \n')
    for predictor in CategoricalPredictorList:
        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)
        AnovaResults = f_oneway(*CategoryGroupLists)

        # If the ANOVA P-Value is <0.05, that means we reject H0
        if (AnovaResults[1] < 0.05):
            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])
            SelectedPredictors.append(predictor)
        else:
            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])

    return(SelectedPredictors)

#Calling the function to check which categorical variables are correlated with target
CategoricalPredictorList=['cut','color','clarity']
FunctionAnova(inpData=diamonds,
              TargetVariable='price',
              CategoricalPredictorList=CategoricalPredictorList)

"""##Observations from Step 16
* The results of ANOVA confirm our visual analysis using box plots above.

* All categorical variables are correlated with the Target variable.
* This is something you can guess by looking at the box plots!

* Final selected Categorical columns:

'cut', 'color', 'clarity'

## Selecting final Predictors/Features for building Machine Learning/AI model.
* Based on the extensive tests with exploratory data analysis, we can select the final features/predictors/columns for machine learning model building as:
* **carat, depth, table,price, x, y, z**
"""

SelectedColumns=['carat','depth','table','price','x','y','z','cut','color','clarity']

# Selecting final columns
DataForML=diamonds[SelectedColumns]
DataForML.head()

# Saving this final data subset for reference during deployment
DataForML.to_pickle('DataForML.pkl')

"""## Step 17: Data Pre-processing for Machine Learning Model Building or Model Development
* List of steps that needs to be performed on predictor variables before data can be used for machine learning

* Converting each Ordinal Categorical columns to numeric
* Converting Binary nominal Categorical columns to numeric using 1/0 mapping
* Converting all other nominal categorical columns to numeric using pd.get_dummies()
* Data Transformation (Optional): Standardization/Normalization/log/sqrt. Important if you are using distance based algorithms like KNN, or Neural Networks
* Converting the ordinal variable to numeric - In this data there is no Ordinal categorical variable.
* Converting the binary nominal variable to numeric using 1/0 mapping: There is no binary nominal variable in string format in this data

## Converting the nominal variable to numeric using get_dummies()
"""

# Treating all the nominal variables at once using dummy variables
DataForML_Numeric=pd.get_dummies(DataForML)

# Adding Target Variable to the data
DataForML_Numeric['price']=diamonds['price']

# Printing sample rows
DataForML_Numeric.head()

"""## Step 18: Machine Learning Model Development:
* Splitting the data into Training and Testing sample
* We dont use the full data for creating the model (training data).
* Some data is randomly selected and kept aside for checking how good the model is.
* This is known as Testing Data and the remaining data is called Training data on which the model is built.
* Typically 70% of data is used as Training data and the rest 30% is used as Tesing data.

"""

# Printing all the column names for our reference
DataForML_Numeric.columns

#Separate Target Variable and Predictor Variables
TargetVariable='price'
Predictors=['carat','depth', 'table','x','y','z']

X=DataForML_Numeric[Predictors].values
y=DataForML_Numeric[TargetVariable].values

# Split the data into training and testing set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)

"""## Step 19: Standardization/Normalization of data
* You can choose not to run this step if you want to compare the resultant accuracy of this transformation with the accuracy of raw data (Optional Step)

* However, if you are using KNN or Neural Networks, then this step becomes necessary.
"""

### Standardization of data ###
from sklearn.preprocessing import StandardScaler, MinMaxScaler
# Choose either standardization or Normalization
# On this data Min Max Normalization produced better results

# Choose between standardization and MinMAx normalization
#PredictorScaler=StandardScaler()
PredictorScaler=MinMaxScaler()

# Storing the fit object for later reference
PredictorScalerFit=PredictorScaler.fit(X)

# Generating the standardized values of X
X=PredictorScalerFit.transform(X)

# Split the data into training and testing set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Sanity check for the sampled data
# For checking the X and y shape of train and actual test
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""## Step 20: Multiple Linear Regression Algorithm For ML/AI model building

"""

#Multiple Linear Regression
from sklearn.linear_model import LinearRegression
RegModel = LinearRegression()

# Printing all the parameters of Linear regression
print(RegModel)

# Creating the model on Training Data
LREG=RegModel.fit(X_train,y_train)
prediction=LREG.predict(X_test)

from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))

###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')

# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)

# Printing sample prediction values
print(TestingDataResults.head())

# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
  TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])

MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])

Accuracy =100 - MAPE
MedianAccuracy=100- MedianMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', MedianAccuracy)

# Defining a custom function to calculate accuracy
# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred):
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)

# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)

# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score

# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

"""## **Decision Tree Regressor**

"""

# Commented out IPython magic to ensure Python compatibility.
# Decision Trees (Multiple if-else statements!)
from sklearn.tree import DecisionTreeRegressor
RegModel = DecisionTreeRegressor(max_depth=5,criterion='friedman_mse')
# Good Range of Max_depth = 2 to 20

# Printing all the parameters of Decision Tree
print(RegModel)

# Creating the model on Training Data
DT=RegModel.fit(X_train,y_train)
prediction=DT.predict(X_test)

from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))

# Plotting the feature importance for Top 10 most important columns
# %matplotlib inline
feature_importances = pd.Series(DT.feature_importances_, index=Predictors)
feature_importances.nlargest(10).plot(kind='barh')

###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')

# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)

# Printing sample prediction values
print(TestingDataResults.head())

# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
  TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])

MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])

Accuracy =100 - MAPE
MedianAccuracy=100- MedianMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', MedianAccuracy)

# Defining a custom function to calculate accuracy
# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred):
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)

# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)

# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score

# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

# Load libraries
from IPython.display import Image
from sklearn import tree
import pydotplus

# Remove the class_names parameter as it's not relevant for regression
dot_data = tree.export_graphviz(RegModel, out_file=None,
                                feature_names=Predictors)

# printing the rules
#print(dot_data)

# Draw graph
graph = pydotplus.graph_from_dot_data(dot_data)

# Show graph
Image(graph.create_png(), width=2000,height=2000)
# Double click on the graph to zoom in

"""# Random Forest Regressor"""

# Commented out IPython magic to ensure Python compatibility.
# Random Forest (Bagging of multiple Decision Trees)
from sklearn.ensemble import RandomForestRegressor
RegModel = RandomForestRegressor(max_depth=4, n_estimators=400,criterion='friedman_mse')
# Good range for max_depth: 2-10 and n_estimators: 100-1000

# Printing all the parameters of Random Forest
print(RegModel)

# Creating the model on Training Data
RF=RegModel.fit(X_train,y_train)
prediction=RF.predict(X_test)

from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))

# Plotting the feature importance for Top 10 most important columns
# %matplotlib inline
feature_importances = pd.Series(RF.feature_importances_, index=Predictors)
feature_importances.nlargest(10).plot(kind='barh')

###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')

# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)

# Printing sample prediction values
print(TestingDataResults.head())

# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
  TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])

MAPE=np.mean(TestingDataResults['APE'])
OpenMAPE=np.median(TestingDataResults['APE'])

Accuracy =100 - MAPE
OpenAccuracy=100- OpenMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', OpenAccuracy)


# Defining a custom function to calculate accuracy
# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred):
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)

# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)

# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score

# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

"""**Step 21: AdaBoost Algorithm For ML/AI model building**"""

# Commented out IPython magic to ensure Python compatibility.
# Adaboost (Boosting of multiple Decision Trees)
from sklearn.ensemble import AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
# Choosing Decision Tree with 6 level as the weak learner
DTR=DecisionTreeRegressor(max_depth=3)
RegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.04)
# Printing all the parameters of Adaboost
print(RegModel)
# Creating the model on Training Data
AB=RegModel.fit(X_train,y_train)
prediction=AB.predict(X_test)
from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))
# Plotting the feature importance for Top 10 most important columns
# %matplotlib inline
feature_importances = pd.Series(AB.feature_importances_, index=Predictors)
feature_importances.nlargest(10).plot(kind='barh')
###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')
# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)
# Printing sample prediction values
print(TestingDataResults.head())
# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])
MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])
Accuracy =100 - MAPE

# Adaboost (Boosting of multiple Decision Trees)


MedianAccuracy=100- MedianMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', MedianAccuracy)

# Defining a custom function to calculate accuracy
# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred): # Removed extra indent here
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)

# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)

# ... (rest of your code)
# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score
# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

"""**XGBoost Regressor**


---



"""

# Commented out IPython magic to ensure Python compatibility.
# Xtreme Gradient Boosting (XGBoost)
from xgboost import XGBRegressor
RegModel=XGBRegressor(max_depth=2,
learning_rate=0.1,
n_estimators=1000,
objective='reg:linear',
booster='gbtree')
# Printing all the parameters of XGBoost
print(RegModel)
# Creating the model on Training Data
XGB=RegModel.fit(X_train,y_train)
prediction=XGB.predict(X_test)
from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))
# Plotting the feature importance for Top 10 most important columns
# %matplotlib inline
feature_importances = pd.Series(XGB.feature_importances_, index=Predictors)
feature_importances.nlargest(10).plot(kind='barh')
###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')
# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)
# Printing sample prediction values
print(TestingDataResults.head())
# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])
MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])
Accuracy =100 - MAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Open Accuracy on test data:', OpenAccuracy)


# Defining a custom function to calculate accuracy
# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred):
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)

# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)

# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score

# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

"""
**Plotting a single Decision tree out of XGBoost**
"""

#Plotting a single Decision tree out of XGBoost
from xgboost import plot_tree
import matplotlib.pyplot as plt
fig, ax = plt.subplots(figsize=(20, 8))
plot_tree(XGB, num_trees=10, ax=ax)

"""# **K-Nearest Neighbor(KNN)**

"""

#kNN
# K-Nearest Neighbor(KNN)
from sklearn.neighbors import KNeighborsRegressor
RegModel = KNeighborsRegressor(n_neighbors=3)
# Printing all the parameters of KNN
print(RegModel)
# Creating the model on Training Data
KNN=RegModel.fit(X_train,y_train)
prediction=KNN.predict(X_test)
from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))
# Plotting the feature importance for Top 10 most important columns
# The variable importance chart is not available for KNN
###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')
# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)
# Printing sample prediction values
print(TestingDataResults.head())
# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])
MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])
Accuracy =100 - MAPE
MedianAccuracy=100- MedianMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', MedianAccuracy)
# Defining a custom function to calculate accuracy

# Make sure there are no zeros in the Target variable if you are using MAPE
def Accuracy_Score(orig,pred):
    MAPE = np.mean(100 * (np.abs(orig-pred)/orig)) # Indent this line
    #print('#'*70,'Accuracy:', 100-MAPE)
    return(100-MAPE)
# Custom Scoring MAPE calculation
from sklearn.metrics import make_scorer
custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)
# Importing cross validation function from sklearn
from sklearn.model_selection import cross_val_score
# Running 10-Fold Cross validation on a given algorithm
# Passing full data X and y because the K-fold will split the data and automatically choose train/test
Accuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)
print('\nAccuracy values for 10-fold Cross Validation:\n',Accuracy_Values)
print('\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))

"""## **Support Vector Machine (SVM) Regressor**

"""

# Commented out IPython magic to ensure Python compatibility.
# Support Vector Machines(SVM)
from sklearn import svm
RegModel = svm.SVR(C=50, kernel='rbf', gamma=0.01)
# Printing all the parameters
print(RegModel)
# Creating the model on Training Data
SVM=RegModel.fit(X_train,y_train)
prediction=SVM.predict(X_test)
from sklearn import metrics
# Measuring Goodness of fit in Training data
print('R2 Value:',metrics.r2_score(y_train, SVM.predict(X_train)))
# Plotting the feature importance for Top 10 most important columns
# The built in attribute SVM.coef_ works only for linear kernel
# %matplotlib inline
#feature_importances = pd.Series(SVM.coef_[0], index=Predictors)
#feature_importances.nlargest(10).plot(kind='barh')
###########################################################################
print('\n##### Model Validation and Accuracy Calculations ##########')
# Printing some sample values of prediction
TestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)
TestingDataResults[TargetVariable]=y_test
TestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)
# Printing sample prediction values
print(TestingDataResults.head())
# Calculating the error for each row
TestingDataResults['APE']=100 * ((abs(
TestingDataResults['price']-TestingDataResults['Predictedprice']))/TestingDataResults['price'])
MAPE=np.mean(TestingDataResults['APE'])
MedianMAPE=np.median(TestingDataResults['APE'])
Accuracy =100 - MAPE
MedianAccuracy=100- MedianMAPE
print('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier
print('Median Accuracy on test data:', MedianAccuracy)

"""# Step 21: Model Deployment
* Deployment of the Model - Based on the above trials we select that algorithm which produces the best average accuracy.

* In this case, multiple algorithms have produced similar kind of average accuracy. Hence, we can choose any one of them.

* I am choosing XGboost as the final model it has the highest accuracy!

* In order to deploy the model we follow steps outlined next.

* Train/Build the model again using 100% data available

* Save the model as a serialized file which can be stored anywhere.

* Create a python function which gets integrated with front-end Viewer(GUI/ Website etc.) to take all the inputs and returns the prediction

* Choosing only the most important variables

* Its beneficial to keep lesser number of predictors for the model while deploying it in production.

* The lesser predictors you keep, the better it is, because the model will be less dependent on predictor columns/features, hence, more stable.

* This is important specially when the data is high dimensional(too many predictor columns/features).

* For this dataset, the most important predictor variables are . As these are consistently on top of the variable importance chart for every algorithm. Hence choosing these as final set of predictor variables will result in better house price prediction platform/system.
"""

# Separate Target Variable and Predictor Variables
TargetVariable='price'

# Selecting the final set of predictors for the deployment
# Based on the variable importance charts of multiple algorithms above
Predictors=['carat','depth', 'table','x','y','z']

X=DataForML_Numeric[Predictors].values
y=DataForML_Numeric[TargetVariable].values

### Sandardization of data ###
from sklearn.preprocessing import StandardScaler, MinMaxScaler
# Choose either standardization or Normalization
# On this data Min Max Normalization produced better results

# Choose between standardization and MinMAx normalization
#PredictorScaler=StandardScaler()
PredictorScaler=MinMaxScaler()

# Storing the fit object for later reference
PredictorScalerFit=PredictorScaler.fit(X)

# Generating the standardized values of X
X=PredictorScalerFit.transform(X)

print(X.shape)
print(y.shape)

"""**# Step 22: Retraining the final model using 100% data**"""

# Training the model on 100% Data available
Final_XGB_Model=RegModel.fit(X,y)

"""**# Step 23: Save the model as a serialized file which can be stored anywhere**"""

import pickle
import os

# Saving the Python objects as serialized files can be done using pickle library
# Here let us save the Final model
with open('Final_XGB_Model.pkl', 'wb') as fileWriteStream:
    pickle.dump(Final_XGB_Model, fileWriteStream)
    # Don't forget to close the filestream!
    fileWriteStream.close()

print('pickle file of Predictive Model is saved at Location:',os.getcwd())

"""**# Step 24: Create a python function**"""

from re import IGNORECASE
import os
# This Function can be called from any from any front end tool/website

def FunctionPredictResult(InputData):
    import pandas as pd
    Num_Inputs=InputData.shape[0]

    # Making sure the input data has same columns as it was used for training the model
    # Also, if standardization/normalization was done, then same must be done for new input

    # Appending the new data with the Training data
    # Check if the file exists before attempting to read it.
    if os.path.exists('DataForML.pkl'):
        DataForML=pd.read_pickle('DataForML.pkl')
        InputData = pd.concat([InputData, DataForML], ignore_index=True)
    else:
        # Handle the case where the file is not found,
        # e.g., by raising an error or using a default dataset.
        raise FileNotFoundError("The file 'DataForML.pkl' was not found. Please make sure it exists in the current directory.")

    # Generating dummy variables for rest of the nominal variables
    InputData=pd.get_dummies(InputData)

    # Maintaining the same order of columns as it was during the model training
    Predictors=['carat','depth', 'table','x','y','z']

    # Generating the input values to the model
    X=InputData[Predictors].values[0:Num_Inputs]

    # Generating the standardized values of X since it was done while model training also
    # Make sure that 'PredictorScalerFit' is defined and accessible in this function.
    X=PredictorScalerFit.transform(X)

    # Loading the Function from pickle file
    import pickle
    with open('Final_XGB_Model.pkl', 'rb') as fileReadStream:
        PredictionModel=pickle.load(fileReadStream)
        # Don't forget to close the filestream!
        fileReadStream.close()

    # Genrating Predictions
    Prediction=PredictionModel.predict(X)
    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])
    return(PredictionResult)

"""**# Step 25: Calling the function for some new data**"""

# Calling the function for some new data
NewSampleData=pd.DataFrame(data=[[0.23,61.5,55,3.95,3.98,2.43],[0.21,59.8,61,3.89,3.84,2.31]],columns=['carat','depth','table','x','y','z'])

print(NewSampleData)

# Calling the Function for prediction
FunctionPredictResult(InputData=NewSampleData)

"""# Conclusion
* The Function FunctionPredictResult() can be used to produce the predictions for one or more new cases at a time.
* Hence, it can be scheduled using a batch job or cron job to run every night and generate predictions for all the house price tasks  in the platform /system.

# Deploying a predictive model as an API
* Django and flask are two popular ways to deploy predictive models as a web service
* You can call your predictive models using a URL from any front end like tableau, java or angular js

# Deploying the model with few parameters
# Function for predictions API
"""

# Creating the function which can take inputs and return prediction
def FunctionGeneratePrediction(inp_carat,inp_depth,inp_table,inp_x, inp_y, inp_z): # Changed argument name here

    # Creating a data frame for the model input
    SampleInputData=pd.DataFrame(
     data=[[inp_carat,inp_depth,inp_table,inp_x, inp_y, inp_z]],
     columns=['carat','depth', 'table','x','y','z'])

    # Calling the function defined above using the input parameters
    Predictions=FunctionPredictResult(InputData= SampleInputData)

    # Returning the predictions
    return(Predictions.to_json())

# Function call
FunctionGeneratePrediction( inp_carat=0.23,inp_depth=61.5,inp_table=55,inp_x=3.95, inp_y=3.98, inp_z=2.43) # Argument name changed to match

"""# Web Deployment using Flask Library/Package
# Installing the flask library required to create the API

"""

!pip install flask

"""# Creating Flask API


"""

from flask import Flask, request, jsonify
import pickle
import pandas as pd
import numpy

app = Flask(__name__)

@app.route('/prediction_api', methods=["GET"])
def prediction_api():
    try:
        # Getting the paramters from API call
        carat_value = float(request.args.get('carat'))
        depth_value = float(request.args.get('depth'))
        table_value = float(request.args.get('table'))
        x_value = float(request.args.get('x'))
        y_value = float(request.args.get('y'))
        z_value = float(request.args.get('z'))


        # Calling the funtion to get predictions
        prediction_from_api=FunctionGeneratePrediction(
                                                       inp_carat,
                                                       inp_depth,
                                                       inp_table,
                                                       inp_x,
                                                       inp_y,
                                                       inp_z
                                                )

        return (prediction_from_api)

    except Exception as e:
        return('Something is not right!:'+str(e))

"""### Starting the API engine"""

import os
  if __name__ =="__main__":

      # Hosting the API in localhost
      app.run(host='127.0.0.1', port=9000, threaded=True, debug=True, use_reloader=False)
      # Interrupt kernel to stop the API

from flask import Flask,request,render_template,jsonify
from src.pipeline.prediction_pipeline import CustomData,PredictPipeline


application=Flask(__name__)

app=application



@app.route('/')
def home_page():
    return render_template('index.html')

@app.route('/predict',methods=['GET','POST'])

def predict_datapoint():
    if request.method=='GET':
        return render_template('form.html')

    else:
        data=CustomData(
            carat=float(request.form.get('carat')),
            depth = float(request.form.get('depth')),
            table = float(request.form.get('table')),
            x = float(request.form.get('x')),
            y = float(request.form.get('y')),
            z = float(request.form.get('z')),
            cut = request.form.get('cut'),
            color= request.form.get('color'),
            clarity = request.form.get('clarity')
        )
        final_new_data=data.get_data_as_dataframe()
        predict_pipeline=PredictPipeline()
        pred=predict_pipeline.predict(final_new_data)

        results=round(pred[0],2)

        return render_template('results.html',final_result=results)






if __name__=="__main__":
    app.run(host='0.0.0.0',debug=True)

import tkinter as tk
from tkinter import ttk, messagebox
import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
import os

class DiamondsPricePredictionApp:
    def __init__(self, master):
        self.master = master
        self.master.title('Diamonds Price Prediction')

        file_path = 'diamonds.csv'
        if not os.path.exists(file_path):
            messagebox.showerror("Error", f"File '{file_path}' not found.")
            return

        self.data = pd.read_csv(file_path)

        # Drop the unnamed index column if it exists
        if 'Unnamed: 0' in self.data.columns:
            self.data = self.data.drop(columns=['Unnamed: 0'])

        self.features = ['carat', 'depth', 'table', 'x', 'y', 'z', 'cut', 'color', 'clarity']
        self.inputs = {}

        # Convert categorical features to numeric using get_dummies
        self.X = pd.get_dummies(self.data.drop('price', axis=1), drop_first=True)
        self.y = self.data['price']

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)

        self.model = XGBRegressor()
        self.model.fit(self.X_train, self.y_train)

        self.create_widgets()

    def create_widgets(self):
        for i, feature in enumerate(self.features):
            label = tk.Label(self.master, text=f'{feature.capitalize()}:')
            label.grid(row=i, column=0, sticky=tk.W, pady=2)

            if feature in ['carat', 'depth', 'table', 'x', 'y', 'z']:
                entry = tk.Entry(self.master)
                entry.grid(row=i, column=1, pady=2)
                self.inputs[feature] = entry
            elif feature == 'cut':
                cut_options = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']
                cut_combobox = ttk.Combobox(self.master, values=cut_options)
                cut_combobox.grid(row=i, column=1, pady=2)
                self.inputs[feature] = cut_combobox
            elif feature == 'color':
                color_options = ['D', 'E', 'F', 'G', 'H', 'I', 'J']
                color_combobox = ttk.Combobox(self.master, values=color_options)
                color_combobox.grid(row=i, column=1, pady=2)
                self.inputs[feature] = color_combobox
            elif feature == 'clarity':
                clarity_options = ['IF', 'VVS1', 'VVS2', 'VS1', 'VS2', 'SI1', 'SI2']
                clarity_combobox = ttk.Combobox(self.master, values=clarity_options)
                clarity_combobox.grid(row=i, column=1, pady=2)
                self.inputs[feature] = clarity_combobox

        predict_button = tk.Button(self.master, text='Submit', command=self.predict_price)
        predict_button.grid(row=len(self.features), column=1, pady=10)

    def predict_price(self):
        # Prepare inputs for prediction
        input_data = {}
        for feature in self.features:
            value = self.inputs[feature].get()
            if feature in ['carat', 'depth', 'table', 'x', 'y', 'z']:
                input_data[feature] = [float(value)]
            else:
                for category in self.X.columns:
                    if category.startswith(feature + '_'):
                        input_data[category] = [1 if category.endswith(value) else 0]

        # Convert input data to DataFrame
        input_df = pd.DataFrame(input_data)

        # Ensure all columns are present
        for column in self.X.columns:
            if column not in input_df.columns:
                input_df[column] = 0

        # Order columns as in training data
        input_df = input_df[self.X.columns]

        # Predict price
        try:
            price = self.model.predict(input_df)
            messagebox.showinfo('Predicted Price', f'The predicted diamond price is ${price[0]:.2f}')
        except Exception as e:
            messagebox.showerror("Error", str(e))

if __name__ == '__main__':
    root = tk.Tk()
    app = DiamondsPricePredictionApp(root)
    root.mainloop()